version: '3.8'

services:
  traefik:
    image: traefik:v3.6
    container_name: traefik
    restart: unless-stopped
    ports:
      - "80:80"
      - "8080:8080"  # Dashboard - secure this in production
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./traefik:/etc/traefik
    command:
      - --log.level=INFO  # Changed from DEBUG for production
      - --api.dashboard=true
      - --api.insecure=true  # TODO: Add auth middleware in production
      - --providers.docker=true
      - --providers.docker.exposedbydefault=false  # Explicit opt-in
      - --entrypoints.web.address=:80
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.traefik.rule=Host(`traefik.local`)"
      - "traefik.http.routers.traefik.service=api@internal"
      - "traefik.http.routers.traefik.entrypoints=web"
    networks:
      - ai-network

  ai-router:
    image: python:3.12-slim
    container_name: ai-router
    restart: unless-stopped
    user: "1000:1000"
    command: bash -c "pip install --no-cache-dir --user -r requirements.txt && python router.py"
    volumes:
      - ./router.py:/app/router.py
      - ./src:/app/src
      - ./requirements.txt:/app/requirements.txt
      - ./config:/app/config
      - ./logs:/var/log/ai-router
    working_dir: /app
    environment:
      - HOME=/tmp
      - TZ=${TZ:-America/Los_Angeles}
      - XAI_API_KEY=${XAI_API_KEY}
      - XAI_SEARCH_TOOLS=${XAI_SEARCH_TOOLS:-web_search,x_search}
      - ROUTER_URL=http://router:8001
      - PRIMARY_URL=http://primary:8000
    depends_on:
      router:
        condition: service_healthy
      primary:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8002/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.ai-router.rule=PathPrefix(`/v1`) || PathPrefix(`/api`) || Path(`/health`) || Path(`/stats`) || Path(`/`)"
      - "traefik.http.routers.ai-router.entrypoints=web"
      - "traefik.http.routers.ai-router.service=ai-router"
      - "traefik.http.services.ai-router.loadbalancer.server.port=8002"
    networks:
      - ai-network

  router:
    image: vllm/vllm-openai:latest
    container_name: vllm-router
    restart: unless-stopped
    runtime: nvidia
    environment:
      - LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu
      - VLLM_USE_MODELSCOPE=false
      - HF_TOKEN=${HF_TOKEN}
    command: >
      --model cyankiwi/Nemotron-Orchestrator-8B-AWQ-4bit
      --dtype half
      --kv-cache-dtype fp8_e4m3
      --gpu-memory-utilization 0.14
      --max-model-len 2048
      --port 8001
      --enforce-eager
      --trust-remote-code
      --enable-prefix-caching
      --disable-log-stats
    volumes:
      - hf-cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']  # Explicitly use GPU 0
              capabilities: [gpu]
        limits:
          memory: 8G  # Much smaller model
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8001/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 180s  # Models take time to load
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.router.rule=PathPrefix(`/router`)"
      - "traefik.http.routers.router.entrypoints=web"
      - "traefik.http.routers.router.service=router"
      - "traefik.http.services.router.loadbalancer.server.port=8001"
      - "traefik.http.middlewares.router-stripprefix.stripprefix.prefixes=/router"
      - "traefik.http.routers.router.middlewares=router-stripprefix"
    networks:
      - ai-network

  primary:
    image: vllm/vllm-openai:latest
    container_name: vllm-primary
    restart: unless-stopped
    runtime: nvidia
    environment:
      - LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu
      - VLLM_USE_MODELSCOPE=false
      - VLLM_USE_FLASHINFER_MOE_FP4=1
      - VLLM_FLASHINFER_MOE_BACKEND=throughput
      - HF_TOKEN=${HF_TOKEN}
    command: >
      --model unsloth/NVIDIA-Nemotron-3-Nano-30B-A3B-NVFP4
      --dtype bfloat16
      --kv-cache-dtype fp8_e4m3
      --gpu-memory-utilization 0.65
      --max-model-len 32768
      --disable-log-stats
      --port 8000
      --enforce-eager
      --trust-remote-code
      --reasoning-parser-plugin /app/nano_v3_reasoning_parser.py
      --reasoning-parser nano_v3
    volumes:
      - ./nano_v3_reasoning_parser.py:/app/nano_v3_reasoning_parser.py
      - hf-cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']  # Same GPU as router
              capabilities: [gpu]
        limits:
          memory: 48G  # Larger model needs more memory
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 180s
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.primary.rule=PathPrefix(`/primary`)"
      - "traefik.http.routers.primary.entrypoints=web"
      - "traefik.http.routers.primary.service=primary"
      - "traefik.http.services.primary.loadbalancer.server.port=8000"
      - "traefik.http.middlewares.primary-stripprefix.stripprefix.prefixes=/primary"
      - "traefik.http.routers.primary.middlewares=primary-stripprefix"
    networks:
      - ai-network

networks:
  ai-network:
    driver: bridge

volumes:
  hf-cache:
    driver: local